{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce76e04-0386-462c-b817-a00466482c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af500b1-d745-4c4e-9707-b1e1710a80dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Page 1: https://www.nykaa.com/luxe/brands/smashbox/c/5108?intcmp=brand_menu,luxe,Smashbox\n",
      "Scraping Page 2: https://www.nykaa.com/luxe/brands/smashbox/c/5108?page_no=2&sort=popularity&intcmp=brand_menu,luxe,Smashbox&eq=desktop\n",
      "Scraping Page 3: https://www.nykaa.com/luxe/brands/smashbox/c/5108?page_no=3&sort=popularity&intcmp=brand_menu,luxe,Smashbox&eq=desktop\n"
     ]
    }
   ],
   "source": [
    "# Set up Selenium options and driver\n",
    "options = Options()\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "# options.add_argument(\"--headless\")  # Optional: Run in headless mode\n",
    "\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Navigate to the page\n",
    "base_url = \"https://www.nykaa.com/luxe/brands/smashbox/c/5108?\"\n",
    "params = \"intcmp=brand_menu,luxe,Smashbox\"\n",
    "paginationNumber = 1\n",
    "\n",
    "# Allow initial time for the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Scroll incrementally until all products are loaded\n",
    "scroll_pause_time = 2  # Wait time after each scroll\n",
    "\n",
    "# Lists to store data\n",
    "productLinks = []\n",
    "products = []\n",
    "\n",
    "while True:\n",
    "\n",
    "    if paginationNumber == 1:\n",
    "        url = f\"{base_url}{params}\"\n",
    "    else:\n",
    "        url = f\"{base_url}page_no={paginationNumber}&sort=popularity&intcmp=brand_menu,luxe,Smashbox&eq=desktop\"\n",
    "    \n",
    "    # Load the Page\n",
    "    driver.get(url)\n",
    "    print(f\"Scraping Page {paginationNumber}: {url}\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Scroll to the bottom of the page\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(scroll_pause_time)\n",
    "\n",
    "    # Wait until the products are loaded\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, '.productWrapper.css-17nge1h'))\n",
    "        )\n",
    "    except TimeoutException:\n",
    "        print(f\"Scraped the Total number of pages: {paginationNumber - 1}\")\n",
    "        break\n",
    "\n",
    "    # Parse the page content with BeautifulSoup\n",
    "    content = driver.page_source\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "    # Find all product items\n",
    "    deygaOrganicProducts = soup.findAll('div', class_='productWrapper css-17nge1h')\n",
    "    if not deygaOrganicProducts:\n",
    "        print(\"No Products found on this page.\")\n",
    "        break\n",
    "\n",
    "    # Extract product links\n",
    "    for product in deygaOrganicProducts:\n",
    "        # Extract the Stock Status\n",
    "        stockTag = product.find('span', class_ = \"css-lg5xc9\")\n",
    "        if stockTag:\n",
    "            stock = stockTag.get_text(strip = True)\n",
    "        else:\n",
    "            stock = \"In Stock\"\n",
    "\n",
    "        # Extract the Product Highlight\n",
    "        highlightTag = product.find(\"li\", class_ = \"custom-tag css-1bse542\")\n",
    "        if highlightTag:\n",
    "            highlight = highlightTag.get_text(strip = True)\n",
    "        else:\n",
    "            highlight = \"None\"\n",
    "\n",
    "        # Extract product link\n",
    "        linkTag = product.find('a', href=True)\n",
    "        if linkTag:\n",
    "            productLink = linkTag['href']\n",
    "            # Check if the link is a relative URL and add the base URL if necessary\n",
    "            if not productLink.startswith(\"http\"):  # Relative URL\n",
    "                productLink = \"https://www.nykaa.com\" + productLink\n",
    "            productLinks.append({\"link\" : productLink, \"stock\" : stock, \"highlight\" : highlight})\n",
    "                \n",
    "    for productData in productLinks:\n",
    "        \n",
    "        link = productData[\"link\"]\n",
    "        stock = productData[\"stock\"]\n",
    "        highlight = productData[\"highlight\"]\n",
    "        \n",
    "        driver.get(link)\n",
    "        time.sleep(3)  # Allow time for the page to load\n",
    "\n",
    "        # Parse individual product page\n",
    "        productPageContent = driver.page_source\n",
    "        productSoup = BeautifulSoup(productPageContent, 'html.parser')\n",
    "    \n",
    "        # Extract Product Name\n",
    "        productTag = productSoup.find('h1', class_='css-1gc4x7i')\n",
    "        if productTag:\n",
    "            prodName = productTag.get_text(strip=True)\n",
    "        else:\n",
    "            prodName = \"No Description Available\"\n",
    "    \n",
    "        # Extract Ratings\n",
    "        ratingTag = productSoup.find('div', class_=\"css-1m0y15j\")\n",
    "        if ratingTag:\n",
    "            ratingText = ratingTag.find('div', class_=\"css-m6n3ou\")\n",
    "            if ratingText:\n",
    "                ratings = ratingText.get_text(strip = True)\n",
    "            else:\n",
    "                ratings = \"N/A\"\n",
    "        else:\n",
    "            ratings = \"N/A\"\n",
    "\n",
    "        # Extract the Ratings & Reviews Count\n",
    "        ratingCountTag = productSoup.find('div', class_ = \"css-1eip5u4\")\n",
    "        if ratingCountTag:\n",
    "            ratingCount = ratingCountTag.get_text(strip = True)\n",
    "        else:\n",
    "            ratingCount = \"None\"\n",
    "\n",
    "        # Extract the Offer Price and Original Price\n",
    "        productDiv = productSoup.find('div', class_ = \"css-1d0jf8e\")\n",
    "\n",
    "        # Extract the first two (span) tags\n",
    "        if productDiv:\n",
    "            spanTags = productDiv.find_all('span')\n",
    "            # print(len(spanTags))\n",
    "\n",
    "            originalPrice = \"N/A\"\n",
    "            offerPrice = \"N/A\"\n",
    "\n",
    "            if len(spanTags) == 2:\n",
    "                originalPrice = spanTags[1].get_text(strip = True)\n",
    "                offerPrice = \"N/A\"\n",
    "            elif len(spanTags) == 4:\n",
    "                originalPrice = spanTags[1].get_text(strip = True)\n",
    "                offerPrice = spanTags[2].get_text(strip = True)\n",
    "\n",
    "            # Print the Values\n",
    "            # print(f\"Original Price: {originalPrice}, Offer Price: {offerPrice}\")\n",
    "\n",
    "        else:\n",
    "            print(\"Product div not found, defaulting to Unavailable for prices\")\n",
    "\n",
    "        # Extract the Discount\n",
    "        discountTag = productSoup.find('span', class_ = \"css-bhhehx\")\n",
    "        if discountTag:\n",
    "            discount = discountTag.get_text(strip = True)\n",
    "        else:\n",
    "            discount = \"No Discount\"\n",
    "\n",
    "        products.append({\n",
    "            \"Product Brand\" : \"Smashbox\",\n",
    "            \"Product Name\" : prodName,\n",
    "            \"Product Rating\" : ratings,\n",
    "            \"Product Rating & Review Count\" : ratingCount,\n",
    "            \"Product Original Price\" : originalPrice, \n",
    "            \"Product Offer Price\" : offerPrice, \n",
    "            \"Product Discount\" : discount,\n",
    "            \"Product Highlight\" : highlight,\n",
    "            \"Product Stock Status\" : stock\n",
    "        })\n",
    "\n",
    "    # Clear the product links list to avoid the duplication\n",
    "    productLinks.clear()\n",
    "\n",
    "    paginationNumber += 1 # Increment the Page Number\n",
    "    time.sleep(5)\n",
    "\n",
    "# Close the browser after scraping\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51788528-745e-417f-9906-7365cb9d74e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Products: \\n {products}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b5cfc4-9ea0-4018-986a-d48313f9fa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "smashbox  = pd.DataFrame(products)\n",
    "smashbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82154c95-b90b-4489-b9b9-6b1f007c9c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smashbox.to_csv(\"C:/Users/Logiya Vidhyapathy/Documents/KGISL Data Science/Project Files and Documents/Capstone Project/Smashbox Products_Nykaa.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
